{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting False Statements\n",
    "\n",
    "Cristian Nuno | May 7, 2019\n",
    "\n",
    "## Question\n",
    "\n",
    "Can we use the content of a statement to predict how likely it is to be true?\n",
    "\n",
    "## Dataset\n",
    "Today we will be using The [LIAR dataset](https://www.cs.ucsb.edu/˜william/data/liar_dataset.zip) from 2017, which includes 12.8K human labeled short statements from [PolitiFact's](https://www.politifact.com/truth-o-meter/article/2018/feb/12/principles-truth-o-meter-politifacts-methodology-i/) [API](https://s3.amazonaws.com/static.politifact.com/api/doc.html). \n",
    "\n",
    "Each statement was evaluated by a PolitiFact editor for its truthfulness. Below captures the labels assigned to each statement within the LIAR dataset:\n",
    "\n",
    "\n",
    "| **Label** | **Description** |\n",
    "| :-------: | :-------------: |\n",
    "| True (`true`) | The statement is accurate and there’s nothing significant missing. |\n",
    "| Mostly True (`mostly-true`) | The statement is accurate but needs clarification or additional information. |\n",
    "| Half True (`half-true`) | The statement is partially accurate but leaves out important details or takes things out of context. |\n",
    "| Barely True* (`barely-true`) | The statement contains an element of truth but ignores critical facts that would give a different impression. |\n",
    "| False (`false`) | The statement is not accurate. |\n",
    "| Pants on Fire (`pants-fire`) | The statement is not accurate and makes a ridiculous claim. |\n",
    "\n",
    "**PolitiFact assigns statements as 'Mostly False' but the creators of the LIAR dataset relabeled it as 'Barely True'*\n",
    "\n",
    "## Example Statements\n",
    "\n",
    "### True\n",
    "\n",
    "> 'The Chicago Bears have had more starting quarterbacks in the last 10 years than the total number of tenured (UW) faculty fired during the last two decades.' - Robin Vos, R-WI State Assembly Speaker\n",
    "\n",
    "### Mostly True\n",
    "\n",
    "> 'Youth unemployment in minority communities is about 40 to 45 percent.' - Peter Kinder, Fmr. Lt. Govenor, R-MO\n",
    "\n",
    "### Half True\n",
    "\n",
    "> 'Says that voter identification laws keep poor people from voting, minorities from voting, the elderly from voting, students from voting.' - Marcia Fudge, D-OH 11th District Representative\n",
    "\n",
    "### Barely True\n",
    "\n",
    "> 'The jobs bill includes President Obamas tax on soup kitchens' - Eric Cantor, Fmr. R-VA 7th Districrt Representative\n",
    "\n",
    "### False\n",
    "\n",
    "> 'I dont know who (Jonathan Gruber) is.' - Nancy Pelosi, Speaker of the House, D-CA 12th District Representative\n",
    "\n",
    "### Pants on Fire\n",
    "\n",
    "> 'In the case of a catastrophic event, the Atlanta-area offices of the Centers for Disease Control and Prevention will self-destruct.' - The Walking Dead\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load necessary modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg' # improve image quality of inline graphics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the column names\n",
    "# note: see the README for more details\n",
    "column_names = [\"id\", \"label\", \"statement\",\n",
    "                \"subject\", \"speaker\", \"speaker_position\",\n",
    "                \"state\", \"party\", \"barely_true_counts\", \n",
    "                \"false_counts\", \"half_true_counts\", \"mostly_true_counts\",\n",
    "                \"pants_on_fire_counts\", \"context\"]\n",
    "\n",
    "# import data\n",
    "news_df = pd.read_csv(\"raw_data/train.tsv\", \n",
    "                      sep=\"\\t\", \n",
    "                      header=None,\n",
    "                      names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['false', 'half-true', 'mostly-true', 'true', 'barely-true',\n",
       "       'pants-fire'], dtype=object)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['label'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create a flag to indicate a statement that contains the \"pants-fire\" `label` value\n",
    "\n",
    "To do this, we'll be creating our own function that is inspired from the [pd.get_dummies()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) function to transform the categorical variable `label` into indicator variables. \n",
    "\n",
    "The name 'dummies' refers the information contained in each of the newly created indicator variables: a 0 or a 1. The value 0 or 1 indicates the absence or presence of some categorical effect that may be expected to influence the outcome (i.e. statements which are extremely false)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(label):\n",
    "    \"\"\"Encode true as 1, pants-on-fire as 0, everything else as None\"\"\"\n",
    "    if label == \"true\":\n",
    "        return 1\n",
    "    elif label == \"pants-fire\" or label == \"false\":\n",
    "        return 0\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df[\"label_numeric\"] = news_df[\"label\"].apply(encode_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = news_df[['statement', 'label_numeric']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>label_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Chicago Bears have had more starting quart...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>When Mitt Romney was governor of Massachusetts...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>McCain opposed a requirement that the governme...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            statement  label_numeric\n",
       "0   Says the Annies List political group supports ...            0.0\n",
       "3   Health care reform legislation is likely to ma...            0.0\n",
       "5   The Chicago Bears have had more starting quart...            1.0\n",
       "12  When Mitt Romney was governor of Massachusetts...            0.0\n",
       "16  McCain opposed a requirement that the governme...            1.0"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that we have our data, let's build our model using two methods\n",
    "\n",
    "### TFIDF\n",
    "Term frequency–inverse document frequency (TFIDF), is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.\n",
    "\n",
    "### Random Forest\n",
    "Random Forest is an ensemble learning method for classification, regression and other tasks that operates by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "tfidf_pipe = Pipeline([('vectorizer', TfidfVectorizer()),\n",
    "                ('model', MultinomialNB())])\n",
    "\n",
    "rf_pipe = Pipeline([('vectorizer', TfidfVectorizer()),\n",
    "                ('model', RandomForestClassifier(n_estimators=100))])\n",
    "\n",
    "# create training and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['statement'],\n",
    "                                                    data['label_numeric'],\n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=...e,\n",
       "        vocabulary=None)), ('model', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_pipe.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pipe.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['In three days last week, (Gov. Rick) Perry flew to five cities at taxpayers expense, holding press conferences, delivering $2,325,000 in checks.',\n",
       "       'What is the proper collective noun for a group of baboons? Believe it or not . . . a Congress!',\n",
       "       'When we took office, let me remind you, there was virtually no international pressure on Iran.',\n",
       "       'Says Saddam Hussein had a 10-year relationship with al-Qaida.',\n",
       "       'The most likely triggering cause of (microcephaly) is the DTaP shot, a vaccine that had been recently mandated by the Brazilian government to be injected into pregnant women.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some false statements\n",
    "false_statements = np.random.choice(X_test[y_test==0], size=5)\n",
    "false_statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.64261609, 0.35738391],\n",
       "       [0.69152126, 0.30847874],\n",
       "       [0.75915142, 0.24084858],\n",
       "       [0.59077478, 0.40922522],\n",
       "       [0.67149034, 0.32850966]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_pipe.predict_proba(false_statements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58, 0.42],\n",
       "       [0.48, 0.52],\n",
       "       [0.58, 0.42],\n",
       "       [0.76, 0.24],\n",
       "       [0.83, 0.17]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pipe.predict_proba(false_statements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['The very first meal on the surface of the moon was the Holy Communion.',\n",
       "       'Under legislation that has cleared the Georgia House, some children who are legal refugees could obtain state scholarships to attend private schools.',\n",
       "       'We have one of the most expensive General Assemblies, per capita, in the entire country.',\n",
       "       'Over the past twenty years, the number of homicides committed with a firearm in the United States has decreased by nearly 40 percent. The number of other crimes involving the use of a firearm has also plummeted, declining by nearly 70 percent.',\n",
       "       'We have one of the most expensive General Assemblies, per capita, in the entire country.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some true statements\n",
    "true_statements = np.random.choice(X_test[y_test==1], size=5)\n",
    "true_statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70321654, 0.29678346],\n",
       "       [0.62922799, 0.37077201],\n",
       "       [0.53058161, 0.46941839],\n",
       "       [0.42896536, 0.57103464],\n",
       "       [0.53058161, 0.46941839]])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_pipe.predict_proba(true_statements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66, 0.34],\n",
       "       [0.42, 0.58],\n",
       "       [0.57, 0.43],\n",
       "       [0.43, 0.57],\n",
       "       [0.57, 0.43]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pipe.predict_proba(true_statements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
